---
title: "Step 3 - Model predictions and create UDs"
format: html
editor: source
editor_options: 
  chunk_output_type: console
---

## Read in saved data and load packages
If you previously stopped after step 2 and want to restart, you have to read in the saved data and load all the packages.

```{r}
#| output: false
load("processed_data/clean_data.RData")
load("processed_data/stat_travel.RData")
packages <- read.csv("packages.csv")$packages
invisible(lapply(packages, library, character.only = TRUE))
```

## Segment data based on movement type

First we will join the bout data so we can separate stationary data from migration data.
```{r}
locs <- locs %>% group_by(deploy_id) %>% arrange(datetime) %>% nest() %>%
  full_join(stat_travel, by="deploy_id")

locs$data <- foreach(i=1:nrow(locs)) %do% {
  cu_add_bouts(locs$data[[i]], locs$bout_tbl[[i]]) 
}

locs <- locs %>% select(-bout_tbl)

locs <- locs %>% unnest(cols=data) %>% ungroup() %>% st_as_sf()
```

Now we will separate the deployments into different bouts so that we are not simultaneously modeling pre and post-migration segments. There are some deployments with multiple bouts within the Mariana Islands, so we will first identify Mariana Island locations then filter the data. We can then easily filter the post-migration data based on `travel==0` and locations that are outside the Mariana buffer. 

```{r}
mariana <- st_bbox(c(xmin=144, xmax=146, ymin=13, ymax=21)) %>% st_as_sfc() %>% st_as_sf(crs=4326) %>%
  osm_coast(keep=0.5) %>% st_transform(st_crs(locs))
mariana100 <- st_buffer(mariana, 100000) %>% st_union() %>% st_as_sf()
locs_mariana <- locs %>% filter(travel==0) %>% st_filter(mariana100)
locs_post <- locs %>% filter(travel==0) %>% st_filter(mariana100, .predicate = st_not_within)
```

The migration trips can be identified by those bouts that are travel bouts and extend beyond the Mariana buffer

```{r}
migration_bouts <- locs %>% filter(travel==1) %>% st_filter(mariana100, .predicate = st_not_within) %>% 
  st_drop_geometry() %>% select(deploy_id, bout) %>% distinct()
locs_migration <- locs %>% filter(travel==1) %>% right_join(migration_bouts, by=c('deploy_id','bout'))
```

Now we will re-project the data to something more appropriate for each type. 
```{r}
locs_mariana <- locs_mariana %>% st_as_sf() 
prj_mariana <- as.numeric(suggest_crs(locs_mariana)$crs_code[[1]])
locs_mariana <- locs_mariana %>% st_transform(prj_mariana) %>%  group_by(deploy_id) %>% nest() %>% arrange(deploy_id)

locs_migration <- locs_migration %>% st_as_sf() 
prj_migration <-  as.numeric(suggest_crs(locs_migration)$crs_code[[1]])
locs_migration <- locs_migration %>% st_transform(prj_migration) %>%  group_by(deploy_id) %>% nest() %>%
  arrange(deploy_id)
```

For the post migration data we will project each one separately because they are in widely different areas geographically. 
```{r}
locs_post <- locs_post %>% st_as_sf() %>% group_by(deploy_id) %>% nest() %>% arrange(deploy_id)
locs_post$prj <- foreach(i=1:nrow(locs_post), .combine = c) %do% {
  as.numeric(suggest_crs(locs_post$data[[i]])$crs_code[[1]])
}
locs_post$data <- foreach(i=1:nrow(locs_post)) %do% {
  st_transform(locs_post$data[[i]], locs_post$prj[[i]])
}
```

Now we can remove deployments that don't have enough data to do anything with...

```{r}
locs_mariana$n <- sapply(locs_mariana$data, nrow)
locs_mariana <- locs_mariana %>% filter(n>=30)

locs_post$n <- sapply(locs_post$data, nrow)
locs_post <- locs_post %>% filter(n>=30)

locs_migration$n <- sapply(locs_migration$data, nrow)
locs_migration<- locs_migration %>% filter(n>=30)
```


## Fit Movement models

Now we can fit movement models to the different data sets. Here we use Just a Brownian motion movement model

```{r}
## Fixing location error to be equal to the nominal diagnostic data values
constr_bm <- list(
  lower=c(0,0, -Inf),
  upper=Inf
)


fit_mariana <- locs_mariana %>% select(deploy_id)
fit_mariana$fit <- foreach(i=1:nrow(fit_mariana)) %do% {
  cu_crw_argos(locs_mariana$data[[i]], bm=TRUE, crw_control=list(constr=constr_bm))
}

## Check for good fit
all(sapply(fit_mariana$fit, class)=="crwFit")

fit_post <- locs_post %>% select(deploy_id)
fit_post$fit <- foreach(i=1:nrow(fit_post)) %do% {
  cu_crw_argos(locs_post$data[[i]], bm=TRUE, crw_control=list(constr=constr_bm))
}

## Check for good fit
all(sapply(fit_post$fit, class)=="crwFit")

fit_migration <- locs_migration %>% select(deploy_id)
fit_migration$fit <- foreach(i=1:nrow(fit_migration)) %do% {
  cu_crw_argos(locs_migration$data[[i]], bm=TRUE, crw_control=list(constr=constr_bm))
}

## Check for good fit
all(sapply(fit_migration$fit, class)=="crwFit")


```


### (Optional) Refit any models that did not work
The model seams to have fit for all animals (all values of the previous output are `"crwFit"`), however, if some did not fit satisfactorily, you can refit with the following code and it might work, e.g. for hypothetical animal 3:
```{r, eval=FALSE}
# fit[[3]] <- cu_crw_argos(locs$data[[3]], bm=TRUE, constr=constr_bm)
```
Sometimes this works because there is a random process to get the starting values and sometimes bad values happen and if you refit it works better. 

[ARG: I'm not really clear on what the code above actually does to "refit"]{.underline}

## Create visibility graph for rerouting

Here a visability graph is created for routing predicted or simulated track locations around land polygons. This is an optional step and you don't need to do this unless you really want to map predictions or samples around land. Here we'll do it for the Mariana Islands data. We can do it for the post migration data in the next code demo (3b)

```{r}
mariana <- mariana %>% st_transform(prj_mariana)
vis_graph <- pathroutr::prt_visgraph(mariana, centroids=TRUE)
```


## Make location predictions and posterior samples of observations 

### Mariana Islands data demo

Here we will make predictions as well as draw simulated true locations conditional on the data observed. We will use the `future` and `doFuture` packages to make use of parallel computing on multiple processors if desired. Use the following code to set up parallel computing. If you don't want to use it, just skip it. The `workers` argument tells the code how many cores to use. You can use the package/function `parallel::detectCores()` if you want to find out how many are available. Can change the number of workers for each computer to ensure it doesn't overload.
```{r}
plan("multisession", workers=4) # uncomment for parallel processing
```

Now we can make predictions using `%dofuture%` loops which are parallel. In the predict call we are also using the `pathroutr` package to route tracks around land. We accomplish this by making predictions at 1 hr intervals and the observations times, then routing the track around land. After that we extract the predicted locations at observation times. In the simulation draws we are just drawing locations at the observed times to account for location error in future analyses. 

```{r}
pred_mariana <- locs_mariana %>% select(deploy_id)
pred_mariana$pred <- foreach(i=1:nrow(pred_mariana),
                             .options.future=list(packages=c("sf","dplyr","crawlUtils"), seed=TRUE)) %dofuture% {
  cu_crw_predict(fit_mariana$fit[[i]], "1 hour", mariana, vis_graph) %>% cu_extract_obst(locs_mariana$data[[i]])
}

sample_mariana <- locs_mariana %>% select(deploy_id)
sample_mariana$sample <- foreach(i=1:nrow(sample_mariana),
                                 .options.future=list(packages=c("sf","dplyr","crawlUtils"), seed=TRUE)) %dofuture% {
  cu_crw_sample(fit_mariana$fit[[i]], 20)
}

# You should always remove the parallel R instances when you are done
plan("sequential")
```

Now we will make predicted tracks for the migration data
```{r}
pred_migration <- locs_migration %>% select(deploy_id)
pred_migration$pred <- foreach(i=1:nrow(pred_migration),
                               .options.future=list(packages=c("sf","dplyr","crawlUtils"))) %do% {
                               cu_crw_predict(fit_migration$fit[[i]])
}
```

Now for the post migration data, which is a little tricky to get the coastline to map predicted locations around land. So we have to get a custom coastline for each data set.

```{r}
pred_post <- locs_post %>% select(deploy_id)
pred_post$pred <- foreach(i=1:nrow(pred_post)) %do% {
  coast <- locs_post$data[[i]] %>% st_buffer(100000) %>% st_union() %>% st_as_sf() %>%
    osm_coast(keep=0.5)
  vis_graph <- pathroutr::prt_visgraph(coast, centroids=TRUE)
  cu_crw_predict(fit_post$fit[[i]], "1 hour", coast, vis_graph) %>% cu_extract_obst(locs_post$data[[i]])
}

sample_post <- locs_post %>% select(deploy_id)
sample_post$sample <- foreach(i=1:nrow(sample_post)) %do% {
  cu_crw_sample(fit_post$fit[[i]], 20)
}
```


## Save data for future steps

```{r}
save(locs_mariana, fit_mariana, pred_mariana, sample_mariana, mariana, prj_mariana, file="processed_data/pred_sample_mariana.RData")
```

```{r}
save(locs_migration, fit_migration, pred_migration, prj_migration, file="processed_data/pred_sample_migration.RData")
```

```{r}
save(locs_post, fit_post, pred_post, sample_post, file="processed_data/pred_sample_post.RData")
```


